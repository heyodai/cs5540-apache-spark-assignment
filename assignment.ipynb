{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 5540 - Group 1 - Apache Spark Assignment\n",
    "\n",
    "This is the submission document for our programming assignment over Apache Spark. \n",
    "\n",
    "The submission was written as a Jupyter notebook but will be exported to a PDF for submission. We can provide the GitHub repo or the original Jupyter notebook if requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.functions import col, split, explode, lower, trim\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "    .appName(\"my-spark-app\")\\\n",
    "    .config(\"spark.sql.catalogImplementation\", \"hive\")\\\n",
    "    .getOrCreate()\n",
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Team Members](#team-members)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Members\n",
    "\n",
    "This assignment was completed by the following team members (Group 1):\n",
    "\n",
    "- Ayushman Das\n",
    "- Koti Paruchuri\n",
    "- Odai Athamneh\n",
    "- Scott Brunton\n",
    "- Varshith Thota"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Question 1 is as follows: \n",
    "\n",
    "> Given file (`/data/shakespeare-1.txt`) contains the scenes from Shakespeareâ€™s plays. You may use this \n",
    "file as an input dataset to identify the following notes for a student of Classical Drama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|word |\n",
      "+-----+\n",
      "|this |\n",
      "|is   |\n",
      "|the  |\n",
      "|100th|\n",
      "|etext|\n",
      "+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tokenize input text file and clean the word column\n",
    "df = spark.read.text(\"data/shakespeare-1.txt\")\n",
    "\n",
    "df = df.select(explode(split(col(\"value\"), \" \")).alias(\"word\"))\n",
    "df = df.select(lower(trim(col(\"word\"))).alias(\"word\"))\n",
    "\n",
    "df.show(5, truncate=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.1\n",
    "\n",
    "The question reads as follows:\n",
    "\n",
    "> How many different countries are mentioned in the whole file? (Regardless of how many times a single country is mentioned, this country only contributes as a single entry). \n",
    "\n",
    "To address this question, we need a dataset of country names. We are using the `country-list.csv` file provided by the professor. The file contains 211 entries. \n",
    "\n",
    "The caveat to this approach is that the dataset may not contain all countries, such as: \n",
    "- Countries that no longer exist\n",
    "- Countries that are misspelled in the original Shakespearean text\n",
    "- Countries where the name or spelling has changed over time\n",
    "\n",
    "Addressing this issue is beyond the scope of this assignment and would likely require some degree of manual curation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|country       |\n",
      "+--------------+\n",
      "|afghanistan   |\n",
      "|albania       |\n",
      "|algeria       |\n",
      "|american samoa|\n",
      "|andorra       |\n",
      "+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load countries dataframe and clean the country column\n",
    "countries = spark.read.csv(\"data/country-list.csv\", header=False)\n",
    "countries = countries.select(lower(trim(\"_c0\")).alias(\"country\"))\n",
    "\n",
    "countries.show(5, truncate=False)\n",
    "countries.count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our list of countries, we can use a simple `.join()` to find the number of countries mentioned in the Shakespearean text. We will use the `Country` column as our key and perform an inner join with the Shakespearean text. This will return a new DataFrame with only the rows that have a match in both DataFrames. We can then use `.count()` to get the number of rows in the resulting DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'Country'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# perform join after converting both columns to lowercase and trimming the country column\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m unique_countries \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mjoin(countries, df\u001b[39m.\u001b[39mword \u001b[39m==\u001b[39m countries\u001b[39m.\u001b[39;49mCountry, \u001b[39m\"\u001b[39m\u001b[39minner\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mselect(\u001b[39m\"\u001b[39m\u001b[39mcountry\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mdistinct()\n\u001b[1;32m      3\u001b[0m unique_countries\u001b[39m.\u001b[39mshow(\u001b[39m5\u001b[39m, truncate\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNumber of unique countries in the text file: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(unique_countries\u001b[39m.\u001b[39mcount()))\n",
      "File \u001b[0;32m~/cs5540-apache-spark-assignment/env/lib/python3.10/site-packages/pyspark/sql/dataframe.py:1988\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1978\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001b[39;00m\n\u001b[1;32m   1979\u001b[0m \n\u001b[1;32m   1980\u001b[0m \u001b[39m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1985\u001b[0m \u001b[39m[Row(age=2), Row(age=5)]\u001b[39;00m\n\u001b[1;32m   1986\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1987\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns:\n\u001b[0;32m-> 1988\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m   1989\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name)\n\u001b[1;32m   1990\u001b[0m     )\n\u001b[1;32m   1991\u001b[0m jc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jdf\u001b[39m.\u001b[39mapply(name)\n\u001b[1;32m   1992\u001b[0m \u001b[39mreturn\u001b[39;00m Column(jc)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Country'"
     ]
    }
   ],
   "source": [
    "# perform join after converting both columns to lowercase and trimming the country column\n",
    "unique_countries = df.join(countries, df.word == countries.country, \"inner\").select(\"country\").distinct()\n",
    "unique_countries.show(5, truncate=False)\n",
    "\n",
    "print(\"Number of unique countries in the text file: {}\".format(unique_countries.count()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52d158634e85a4a13156a2aa9aa4d203fab0b0eaa50959d6ad1d28e12f0e62a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
